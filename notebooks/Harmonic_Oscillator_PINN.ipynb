{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f27e1533-dbae-4099-a1bd-26319c1254b9",
   "metadata": {},
   "source": [
    "# Physics informed neural network (PINN) examples\n",
    "In this demo we will code a PINN from scratch in `PyTorch` and use it to solve simulation and inversion problems related to the damped harmonic oscillator.\n",
    "\n",
    "Examples from this notebook are compiled from a series of lectures and workshops by Dr. Ben Moseley\n",
    "\n",
    "https://github.com/benmoseley\n",
    "\n",
    "https://benmoseley.blog/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77dd40bd-f829-41b4-b24f-bc3e43151be5",
   "metadata": {},
   "source": [
    "We are going to use a PINN to solve problems related to the **damped harmonic oscillator**:\n",
    "\n",
    "<img src=\"animations/oscillator.gif\" width=\"500\">\n",
    "\n",
    "We are interested in modelling the displacement of the mass on a spring (green box) over time.\n",
    "\n",
    "This is a canonical physics problem, where the displacement, $u(t)$, of the oscillator as a function of time can be described by the following differential equation:\n",
    "\n",
    "$$\n",
    "m \\dfrac{d^2 u}{d t^2} + \\mu \\dfrac{d u}{d t} + ku = 0~,\n",
    "$$\n",
    "\n",
    "where $m$ is the mass of the oscillator, $\\mu$ is the coefficient of friction and $k$ is the spring constant.\n",
    "\n",
    "We will focus on solving the problem in the **under-damped state**, i.e. where the oscillation is slowly damped by friction (as displayed in the animation above). \n",
    "\n",
    "Mathematically, this occurs when:\n",
    "\n",
    "$$\n",
    "\\delta < \\omega_0~,~~~~~\\mathrm{where}~~\\delta = \\dfrac{\\mu}{2m}~,~\\omega_0 = \\sqrt{\\dfrac{k}{m}}~.\n",
    "$$\n",
    "\n",
    "Furthermore, we consider the following initial conditions of the system:\n",
    "\n",
    "$$\n",
    "u(t=0) = 1~~,~~\\dfrac{d u}{d t}(t=0) = 0~.\n",
    "$$\n",
    "\n",
    "For this particular case, the exact solution is known and given by:\n",
    "\n",
    "$$\n",
    "u(t) = e^{-\\delta t}(2 A \\cos(\\phi + \\omega t))~,~~~~~\\mathrm{with}~~\\omega=\\sqrt{\\omega_0^2 - \\delta^2}~.\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "For a more detailed mathematical description of the harmonic oscillator, check out this blog post: https://beltoforion.de/en/harmonic_oscillator/.\n",
    "\n",
    "## Workflow overview\n",
    "\n",
    "There are **two scientific tasks** related to the harmonic oscillator we will use a PINN for:\n",
    "\n",
    ">First, we will **simulate** the system using a PINN, given its initial conditions.\n",
    "\n",
    ">Second, we will **invert** for underlying parameters of the system using a PINN, given some noisy observations of the oscillator's displacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97248338-2c3c-4456-9b1e-98b1bea3932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b2f5ee0-70fe-4ac9-a8a6-12652ec2a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gif_PIL(outfile, files, fps=5, loop=0):\n",
    "    \"Helper function for saving GIFs\"\n",
    "    imgs = [Image.open(file) for file in files]\n",
    "    imgs[0].save(fp=outfile, format='GIF', append_images=imgs[1:], save_all=True, duration=int(1000/fps), loop=loop)\n",
    "    \n",
    "def oscillator(d, w0, x):\n",
    "    \"\"\"Defines the analytical solution to the 1D underdamped harmonic oscillator problem. \n",
    "    Equations taken from: https://beltoforion.de/en/harmonic_oscillator/\"\"\"\n",
    "    assert d < w0\n",
    "    w = np.sqrt(w0**2-d**2)\n",
    "    phi = np.arctan(-d/w)\n",
    "    A = 1/(2*np.cos(phi))\n",
    "    cos = torch.cos(phi+w*x)\n",
    "    sin = torch.sin(phi+w*x)\n",
    "    exp = torch.exp(-d*x)\n",
    "    y  = exp*2*A*cos\n",
    "    return y\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    \"Defines a connected network\"\n",
    "    \n",
    "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
    "        super().__init__()\n",
    "        activation = nn.Tanh\n",
    "        self.fcs = nn.Sequential(*[\n",
    "                        nn.Linear(N_INPUT, N_HIDDEN),\n",
    "                        activation()])\n",
    "        self.fch = nn.Sequential(*[\n",
    "                        nn.Sequential(*[\n",
    "                            nn.Linear(N_HIDDEN, N_HIDDEN),\n",
    "                            activation()]) for _ in range(N_LAYERS-1)])\n",
    "        self.fce = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fcs(x)\n",
    "        x = self.fch(x)\n",
    "        x = self.fce(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781d0e44-cf5d-449d-8c1e-566143660edd",
   "metadata": {},
   "source": [
    "## Task 1: train a PINN to simulate the system\n",
    "\n",
    "#### Task\n",
    "\n",
    "The first task is to use a PINN to **simulate** the system.\n",
    "\n",
    "Specifically, our inputs and outputs are:\n",
    "\n",
    "- Inputs: underlying differential equation and the initial conditions of the system\n",
    "- Outputs: estimate of the solution, $u(t)$\n",
    "\n",
    "#### Approach\n",
    "\n",
    "The PINN is trained to directly approximate the solution to the differential equation, i.e.\n",
    "\n",
    "$$\n",
    "N\\!N(t;\\theta) \\approx u(t)~,\n",
    "$$\n",
    "\n",
    "For this task, we use $\\delta=2$, $\\omega_0=20$, $m=1$, and try to learn the solution over the domain $t\\in [0,1]$.\n",
    "\n",
    "#### Loss function\n",
    "\n",
    "To simulate the system, the PINN is trained with the following loss function:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\theta)= (N\\!N(0;\\theta) - 1)^2 + \\lambda_1 \\left(\\frac{d N\\!N}{dt}(0;\\theta) - 0\\right)^2 + \\frac{\\lambda_2}{N} \\sum^{N}_{i} \\left( \\left[ m\\frac{d^2}{dt^2} + \\mu \\frac{d}{dt} + k \\right] N\\!N(t_{i};\\theta)  \\right)^2\n",
    "$$\n",
    "\n",
    "#### Computing gradients\n",
    "\n",
    "To compute gradients of the neural network with respect to its inputs, we will use `torch.autograd.grad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16944968-b17c-4655-a5ee-5c103a4fd2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# define a neural network to train\n",
    "pinn = FCN(1,1,32,3)\n",
    "\n",
    "#!!!\n",
    "# define boundary points, for the boundary loss\n",
    "t_boundary = torch.tensor(0.).view(-1,1).requires_grad_(True)# (1, 1)\n",
    "\n",
    "#!!!\n",
    "# define training points over the entire domain, for the physics loss\n",
    "t_physics = torch.linspace(0,1,30).view(-1,1).requires_grad_(True)# (30, 1)\n",
    "\n",
    "# train the PINN\n",
    "d, w0 = 2, 20\n",
    "mu, k = 2*d, w0**2\n",
    "t_test = torch.linspace(0,1,300).view(-1,1)\n",
    "u_exact = oscillator(d, w0, t_test)\n",
    "optimizer = torch.optim.Adam(pinn.parameters(),lr=1e-3)\n",
    "\n",
    "# List to hold the images for the gif\n",
    "files=[]\n",
    "\n",
    "num_epochs = 15001\n",
    "GEN_GIF=True\n",
    "for i in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # compute each term of the PINN loss function above\n",
    "    # using the following hyperparameters\n",
    "    lambda1, lambda2 = 1e-1, 1e-4\n",
    "    \n",
    "    # compute boundary loss\n",
    "    u = pinn(t_boundary)# (1, 1)\n",
    "    loss1 = (torch.squeeze(u) - 1)**2\n",
    "\n",
    "    dudt = torch.autograd.grad(u, t_boundary, torch.ones_like(u), create_graph=True)[0]# (1, 1)\n",
    "    loss2 = (torch.squeeze(dudt) - 0)**2\n",
    "    \n",
    "\n",
    "    # compute physics loss\n",
    "    u = pinn(t_physics)# (30, 1)\n",
    "    dudt = torch.autograd.grad(u, t_physics, torch.ones_like(u), create_graph=True)[0]# (30, 1)\n",
    "    d2udt2 = torch.autograd.grad(dudt, t_physics, torch.ones_like(dudt), create_graph=True)[0]# (30, 1)\n",
    "    loss3 = torch.mean((d2udt2 + mu*dudt + k*u)**2)\n",
    "    \n",
    "    # backpropagate joint loss, take optimiser step\n",
    "    loss = loss1 + lambda1*loss2 + lambda2*loss3\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # plot the result as training progresses\n",
    "    if i % 100 == 0: \n",
    "        u = pinn(t_test).detach()\n",
    "        plt.figure(figsize=(6,2.5))\n",
    "        plt.scatter(t_physics.detach()[:,0], \n",
    "                    torch.zeros_like(t_physics)[:,0], s=20, lw=0, color=\"tab:green\", alpha=0.6)\n",
    "        plt.scatter(t_boundary.detach()[:,0], \n",
    "                    torch.zeros_like(t_boundary)[:,0], s=20, lw=0, color=\"tab:red\", alpha=0.6)\n",
    "        plt.plot(t_test[:,0], u_exact[:,0], label=\"Exact solution\", color=\"tab:grey\", alpha=0.6)\n",
    "        plt.plot(t_test[:,0], u[:,0], label=\"PINN solution\", color=\"tab:green\")\n",
    "        plt.title(f\"Training step {i}\")\n",
    "        plt.legend()\n",
    "        if GEN_GIF:\n",
    "            file = \"plots/task1_%.8i.png\"%(i+1)\n",
    "            plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
    "            files.append(file)\n",
    "    \n",
    "        if i % 5000 == 0: plt.show()\n",
    "        else: plt.close(\"all\")\n",
    "\n",
    "if GEN_GIF:\n",
    "    save_gif_PIL(\"animations/task1.gif\", files, fps=20, loop=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c6138-fead-46a1-8c85-d6075095755b",
   "metadata": {},
   "source": [
    "## Task 2: train a PINN to invert for underlying parameters\n",
    "\n",
    "#### Task\n",
    "\n",
    "The second task is to use a PINN to **invert** for underlying parameters.\n",
    "\n",
    "Specifically, our inputs and outputs are:\n",
    "\n",
    "- Inputs: noisy observations of the oscillator's displacement, $u_{\\mathrm{obs}}$\n",
    "- Outputs: estimate $\\mu$, the coefficient of friction\n",
    "\n",
    "#### Approach\n",
    "\n",
    "Similar to above, the PINN is trained to directly approximate the solution to the differential equation, i.e.\n",
    "\n",
    "$$\n",
    "N\\!N(t;\\theta) \\approx u(t)~,\n",
    "$$\n",
    "\n",
    "However here we assume $\\mu$ is **not known** and we treat it as an additional **learnable parameter** when training the PINN.\n",
    "\n",
    "#### Loss function\n",
    "\n",
    "The PINN is trained with the loss function:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\theta, \\mu)= \\frac{1}{N} \\sum^{N}_{i} \\left( \\left[ m\\frac{d^2}{dt^2} + \\mu \\frac{d}{dt} + k \\right] N\\!N(t_{i};\\theta)  \\right)^2 + \\frac{\\lambda}{M} \\sum^{M}_{j} \\left( N\\!N(t_{j};\\theta) - u_{\\mathrm{obs}}(t_{j}) \\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da357e-534e-4806-8ccb-7be7baf98d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create some noisy observational data\n",
    "torch.manual_seed(123)\n",
    "d, w0 = 2, 20\n",
    "print(f\"True value of mu: {2*d}\")\n",
    "t_obs = torch.rand(40).view(-1,1)\n",
    "u_obs = oscillator(d, w0, t_obs) + 0.04*torch.randn_like(t_obs)\n",
    "t_test = torch.linspace(0,1,300).view(-1,1)\n",
    "u_exact = oscillator(d, w0, t_test)\n",
    "\n",
    "plt.figure(figsize=(6,2.5))\n",
    "plt.title(\"Noisy observational data\")\n",
    "plt.scatter(t_obs[:,0], u_obs[:,0])\n",
    "plt.plot(t_test[:,0], u_exact[:,0], label=\"Exact solution\", color=\"tab:grey\", alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45682d2-4ac4-4809-8d42-5ebd62b9b8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# define a neural network to train\n",
    "pinn = FCN(1,1,32,3)\n",
    "\n",
    "# define training points over the entire domain, for the physics loss\n",
    "t_physics = torch.linspace(0,1,30).view(-1,1).requires_grad_(True)# (30, 1)\n",
    "\n",
    "# train the PINN\n",
    "d, w0 = 2, 20\n",
    "_, k = 2*d, w0**2\n",
    "t_test = torch.linspace(0,1,300).view(-1,1)\n",
    "u_exact = oscillator(d, w0, t_test)\n",
    "\n",
    "# treat mu as a learnable parameter, add it to optimiser\n",
    "mu = torch.nn.Parameter(torch.zeros(1, requires_grad=True))\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(list(pinn.parameters())+[mu],lr=1e-3)\n",
    "mus = []\n",
    "files = []\n",
    "GEN_GIF=True\n",
    "for i in range(15001):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # compute each term of the PINN loss function above\n",
    "    # using the following hyperparameters\n",
    "    lambda1 = 1e4\n",
    "    \n",
    "    # compute physics loss\n",
    "    u = pinn(t_physics)# (30, 1)\n",
    "    dudt = torch.autograd.grad(u, t_physics, torch.ones_like(u), create_graph=True)[0]# (30, 1)\n",
    "    d2udt2 = torch.autograd.grad(dudt, t_physics, torch.ones_like(dudt), create_graph=True)[0]# (30, 1)\n",
    "    loss1 = torch.mean((d2udt2 + mu*dudt + k*u)**2)\n",
    "    \n",
    "    # compute data loss\n",
    "    u = pinn(t_obs)\n",
    "    loss2 = torch.mean((u - u_obs)**2)\n",
    "    \n",
    "    # backpropagate joint loss, take optimiser step\n",
    "    loss = loss1 + lambda1*loss2\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # record mu value\n",
    "    mus.append(mu.item())\n",
    "\n",
    "     # plot the result as training progresses\n",
    "    if i % 100 == 0: \n",
    "        u = pinn(t_test).detach()\n",
    "        plt.figure(figsize=(12,2.5))\n",
    "        \n",
    "        plt.subplot(1,2,1)\n",
    "        plt.scatter(t_obs[:,0], u_obs[:,0], label=\"Noisy observations\", alpha=0.6, color=\"tab:blue\")\n",
    "        plt.plot(t_test[:,0], u[:,0], label=\"PINN solution\", color=\"tab:green\")\n",
    "        plt.title(f\"Training step {i}\")\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(1,2,2)\n",
    "        plt.title(r\"$\\mu$\")\n",
    "        plt.plot(mus, label=\"PINN estimate\", color=\"tab:green\")\n",
    "        plt.hlines(2*d, 0, len(mus), label=\"True value\", color=\"tab:grey\")\n",
    "        plt.xlabel(\"Training step\")\n",
    "        plt.legend()\n",
    "        if GEN_GIF:\n",
    "            file = \"plots/task2_%.8i.png\"%(i+1)\n",
    "            plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
    "            files.append(file)\n",
    "        \n",
    "        if i % 5000 == 0: plt.show()\n",
    "        else: plt.close('all')\n",
    "    \n",
    "\n",
    "if GEN_GIF:\n",
    "    save_gif_PIL(\"animations/task2.gif\", files, fps=20, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cf0bb3-8f7a-4276-a823-556c7dc40eca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
